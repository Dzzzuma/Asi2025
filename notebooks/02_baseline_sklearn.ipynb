{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kształty zbiorów:\n",
      "X_train: (400, 28)\n",
      "X_test: (100, 28)\n",
      "y_train: (400,)\n",
      "y_test: (100,)\n",
      "\n",
      "Satisfaction\n",
      "1    204\n",
      "0    196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "F1-score: 0.8776\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "DATA = Path(\"..\") / \"data\" / \"02_interim\"\n",
    "\n",
    "X_train = np.load(DATA / \"X_train_ready.npy\")\n",
    "X_test  = np.load(DATA / \"X_test_ready.npy\")\n",
    "y_train = pd.read_csv(DATA / \"y_train.csv\").squeeze(\"columns\")\n",
    "y_test  = pd.read_csv(DATA / \"y_test.csv\").squeeze(\"columns\")\n",
    "\n",
    "print(\"Kształty zbiorów:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "# ====== MAPOWANIE ETYKIET NA 0/1 ======\n",
    "label_map = {'Satisfied': 1, 'Neutral or Dissatisfied': 0}\n",
    "y_train_bin = y_train.map(label_map).astype(\"int8\")\n",
    "y_test_bin  = y_test.map(label_map).astype(\"int8\")\n",
    "\n",
    "print(\"\\nLiczność klas w zbiorze treningowym:\")\n",
    "print(y_train_bin.value_counts())\n",
    "\n",
    "# ====== MODEL BASELINE ======\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=2000, random_state=42)\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train_bin)\n",
    "\n",
    "# ====== EWALUACJA (JEDNA METRYKA: F1-score) ======\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test_bin, y_pred)\n",
    "\n",
    "print(\"\\n=== WYNIK BASELINE ===\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podsumowanie baseline\n",
    "\n",
    "Uruchomiono prosty model **LogisticRegression** (pipeline: StandardScaler + LogisticRegression).  \n",
    "Model trenowano na danych z `data/02_interim`.  \n",
    "\n",
    "Wynik na zbiorze testowym:\n",
    "- **F1-score:** 0.8544  \n",
    "\n",
    "Wybrano metrykę **F1**
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (asi-ml)",
   "language": "python",
   "name": "asi-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
